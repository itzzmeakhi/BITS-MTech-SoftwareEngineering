{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "74UC8EcOT7Vn"
      },
      "outputs": [],
      "source": [
        "# importing all required libraries\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "\n",
        "# Banknote Authentication Dataset\n",
        "\n",
        "banknote_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt', header=None, names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])\n",
        "X_banknote = banknote_data.drop('class', axis=1)\n",
        "y_banknote = banknote_data['class']\n",
        "\n",
        "print(\"\\n Banknote Dataset Description:\")\n",
        "print(f\"  Number of features: {X_banknote.shape[1]}\")\n",
        "print(f\"  Number of instances: {X_banknote.shape[0]}\")\n",
        "print(f\"  Number of classes: {len(y_banknote.unique())}\")\n",
        "print(\"  Features:\", list(X_banknote.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTOCofZSXZLE",
        "outputId": "f1265f8a-719f-4aed-dcf0-fc8a77d95a5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Banknote Dataset Description:\n",
            "  Number of features: 4\n",
            "  Number of instances: 1372\n",
            "  Number of classes: 2\n",
            "  Features: ['variance', 'skewness', 'curtosis', 'entropy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Haberman Dataset\n",
        "\n",
        "haberman_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data', header=None, names=['age', 'year', 'nodes', 'survival'])\n",
        "X_haberman = haberman_data.drop('survival', axis=1)\n",
        "y_haberman = haberman_data['survival'].map({1: 1, 2: 0})\n",
        "\n",
        "# Dataset Description\n",
        "print(\"\\n Haberman Dataset Description:\")\n",
        "print(f\"  Number of features: {X_haberman.shape[1]}\")\n",
        "print(f\"  Number of instances: {X_haberman.shape[0]}\")\n",
        "print(f\"  Number of classes: {len(y_haberman.unique())}\")\n",
        "print(\"  Features:\", list(X_haberman.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XtkJQVNX4AD",
        "outputId": "16b5fe13-b303-4627-985f-e64b954d4aa7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Haberman Dataset Description:\n",
            "  Number of features: 3\n",
            "  Number of instances: 306\n",
            "  Number of classes: 2\n",
            "  Features: ['age', 'year', 'nodes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing datasets\n",
        "\n",
        "scaler_banknote_data = StandardScaler()\n",
        "X_banknote_scaled_data = scaler_banknote_data.fit_transform(X_banknote)\n",
        "\n",
        "scaler_haberman_data = StandardScaler()\n",
        "X_haberman_scaled_data = scaler_haberman_data.fit_transform(X_haberman)"
      ],
      "metadata": {
        "id": "0uT2ZQZUZXuD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split with 80% train data and 20% test data\n",
        "\n",
        "X_banknote_train, X_banknote_test, y_banknote_train, y_banknote_test = train_test_split(X_banknote_scaled_data, y_banknote, test_size=0.2, random_state=42, stratify=y_banknote)\n",
        "X_haberman_train, X_haberman_test, y_haberman_train, y_haberman_test = train_test_split(X_haberman_scaled_data, y_haberman, test_size=0.2, random_state=42, stratify=y_haberman)"
      ],
      "metadata": {
        "id": "9IjM0Ai_ZuNl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training and Evaluation\n",
        "\n",
        "results = {}\n",
        "\n",
        "results['banknote'] = {}\n",
        "\n",
        "# Banknote Authentication Models\n",
        "\n",
        "# 1. Naive Bayes\n",
        "\n",
        "print(\"Banknote Authentication Dataset \\n\")\n",
        "print(\"Training Naive Bayes \\n\")\n",
        "\n",
        "nb_banknote = GaussianNB()\n",
        "nb_banknote.fit(X_banknote_train, y_banknote_train)\n",
        "y_banknote_pred_nb = nb_banknote.predict(X_banknote_test)\n",
        "results['banknote']['Naive Bayes'] = {\n",
        "    'Accuracy': round(accuracy_score(y_banknote_test, y_banknote_pred_nb), 4),\n",
        "    'Macro F1-Score': round(f1_score(y_banknote_test, y_banknote_pred_nb, average='macro'), 4),\n",
        "    'Macro Precision': round(precision_score(y_banknote_test, y_banknote_pred_nb, average='macro'), 4),\n",
        "    'Macro Recall': round(recall_score(y_banknote_test, y_banknote_pred_nb, average='macro'), 4)\n",
        "}\n",
        "\n",
        "print(f\"Naive Bayes Results: {results['banknote']['Naive Bayes']} \\n\")\n",
        "print(\"\\n---------------------------------------------------------\\n\")\n",
        "\n",
        "# 2. Logistic Regression\n",
        "\n",
        "print(\"Training Logistic Regression \\n\")\n",
        "\n",
        "lr_banknote = LogisticRegression(random_state=42)\n",
        "param_grid_lr_banknote = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['liblinear']}\n",
        "grid_search_lr_banknote = GridSearchCV(lr_banknote, param_grid_lr_banknote, cv=5, scoring='f1_macro')\n",
        "grid_search_lr_banknote.fit(X_banknote_train, y_banknote_train)\n",
        "best_lr_banknote = grid_search_lr_banknote.best_estimator_\n",
        "y_banknote_pred_lr = best_lr_banknote.predict(X_banknote_test)\n",
        "results['banknote']['Logistic Regression'] = {\n",
        "    'Accuracy': round(accuracy_score(y_banknote_test, y_banknote_pred_lr), 4),\n",
        "    'Macro F1-Score': round(f1_score(y_banknote_test, y_banknote_pred_lr, average='macro'), 4),\n",
        "    'Macro Precision': round(precision_score(y_banknote_test, y_banknote_pred_lr, average='macro'), 4),\n",
        "    'Macro Recall': round(recall_score(y_banknote_test, y_banknote_pred_lr, average='macro'), 4)\n",
        "}\n",
        "\n",
        "print(f\"Logistic Regression Results: {results['banknote']['Logistic Regression']} \\n\")\n",
        "print(f\"Best Logistic Regression parameters: {grid_search_lr_banknote.best_params_} \\n\")\n",
        "print(\"\\n---------------------------------------------------------\\n\")\n",
        "\n",
        "# 3. Support Vector Machine (SVM)\n",
        "\n",
        "print(\"Training SVM \\n\")\n",
        "\n",
        "svm_banknote = SVC(random_state=42)\n",
        "param_grid_svm_banknote = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
        "grid_search_svm_banknote = GridSearchCV(svm_banknote, param_grid_svm_banknote, cv=5, scoring='f1_macro')\n",
        "grid_search_svm_banknote.fit(X_banknote_train, y_banknote_train)\n",
        "best_svm_banknote = grid_search_svm_banknote.best_estimator_\n",
        "y_banknote_pred_svm = best_svm_banknote.predict(X_banknote_test)\n",
        "results['banknote']['SVM'] = {\n",
        "    'Accuracy': round(accuracy_score(y_banknote_test, y_banknote_pred_svm), 4),\n",
        "    'Macro F1-Score': round(f1_score(y_banknote_test, y_banknote_pred_svm, average='macro'), 4),\n",
        "    'Macro Precision': round(precision_score(y_banknote_test, y_banknote_pred_svm, average='macro'), 4),\n",
        "    'Macro Recall': round(recall_score(y_banknote_test, y_banknote_pred_svm, average='macro'), 4)\n",
        "}\n",
        "print(f\"SVM Results: {results['banknote']['SVM']} \\n\")\n",
        "print(f\"Best SVM parameters: {grid_search_svm_banknote.best_params_} \\n\")\n",
        "print(\"\\n---------------------------------------------------------\\n\")\n",
        "\n",
        "print(\"Haberman Dataset \\n\")\n",
        "\n",
        "results['haberman'] = {}\n",
        "\n",
        "# 1. Naive Bayes\n",
        "\n",
        "print(\"Training Naive Bayes \\n\")\n",
        "\n",
        "nb_haberman = GaussianNB()\n",
        "nb_haberman.fit(X_haberman_train, y_haberman_train)\n",
        "y_haberman_pred_nb = nb_haberman.predict(X_haberman_test)\n",
        "results['haberman']['Naive Bayes'] = {\n",
        "    'Accuracy': round(accuracy_score(y_haberman_test, y_haberman_pred_nb), 4),\n",
        "    'Macro F1-Score': round(f1_score(y_haberman_test, y_haberman_pred_nb, average='macro'), 4),\n",
        "    'Macro Precision': round(precision_score(y_haberman_test, y_haberman_pred_nb, average='macro'), 4),\n",
        "    'Macro Recall': round(recall_score(y_haberman_test, y_haberman_pred_nb, average='macro'), 4)\n",
        "}\n",
        "\n",
        "print(f\"Naive Bayes Results: {results['haberman']['Naive Bayes']} \\n\")\n",
        "print(\"\\n---------------------------------------------------------\\n\")\n",
        "\n",
        "# 2. Logistic Regression\n",
        "\n",
        "print(\"Training Logistic Regression \\n\")\n",
        "\n",
        "lr_haberman = LogisticRegression(random_state=42)\n",
        "param_grid_lr_haberman = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['liblinear']}\n",
        "grid_search_lr_haberman = GridSearchCV(lr_haberman, param_grid_lr_haberman, cv=5, scoring='f1_macro')\n",
        "grid_search_lr_haberman.fit(X_haberman_train, y_haberman_train)\n",
        "best_lr_haberman = grid_search_lr_haberman.best_estimator_\n",
        "y_haberman_pred_lr = best_lr_haberman.predict(X_haberman_test)\n",
        "results['haberman']['Logistic Regression'] = {\n",
        "    'Accuracy': round(accuracy_score(y_haberman_test, y_haberman_pred_lr), 4),\n",
        "    'Macro F1-Score': round(f1_score(y_haberman_test, y_haberman_pred_lr, average='macro'), 4),\n",
        "    'Macro Precision': round(precision_score(y_haberman_test, y_haberman_pred_lr, average='macro'), 4),\n",
        "    'Macro Recall': round(recall_score(y_haberman_test, y_haberman_pred_lr, average='macro'), 4)\n",
        "}\n",
        "\n",
        "print(f\"Logistic Regression Results: {results['haberman']['Logistic Regression']} \\n\")\n",
        "print(f\"Best Logistic Regression parameters: {grid_search_lr_haberman.best_params_} \\n\")\n",
        "print(\"\\n---------------------------------------------------------\\n\")\n",
        "\n",
        "# 3. Support Vector Machine (SVM)\n",
        "\n",
        "print(\"Training SVM \\n\")\n",
        "\n",
        "svm_haberman = SVC(random_state=42)\n",
        "param_grid_svm_haberman = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
        "grid_search_svm_haberman = GridSearchCV(svm_haberman, param_grid_svm_haberman, cv=5, scoring='f1_macro')\n",
        "grid_search_svm_haberman.fit(X_haberman_train, y_haberman_train)\n",
        "best_svm_haberman = grid_search_svm_haberman.best_estimator_\n",
        "y_haberman_pred_svm = best_svm_haberman.predict(X_haberman_test)\n",
        "results['haberman']['SVM'] = {\n",
        "    'Accuracy': round(accuracy_score(y_haberman_test, y_haberman_pred_svm), 4),\n",
        "    'Macro F1-Score': round(f1_score(y_haberman_test, y_haberman_pred_svm, average='macro'), 4),\n",
        "    'Macro Precision': round(precision_score(y_haberman_test, y_haberman_pred_svm, average='macro'), 4),\n",
        "    'Macro Recall': round(recall_score(y_haberman_test, y_haberman_pred_svm, average='macro'), 4)\n",
        "}\n",
        "\n",
        "print(f\"SVM Results: {results['haberman']['SVM']} \\n\")\n",
        "print(f\"Best SVM parameters: {grid_search_svm_haberman.best_params_} \\n\")\n",
        "print(\"\\n---------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbJetp_LaYn9",
        "outputId": "0fab3c67-fe0d-48c4-c2c2-616cdf76baf2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banknote Authentication Dataset \n",
            "\n",
            "Training Naive Bayes \n",
            "\n",
            "Naive Bayes Results: {'Accuracy': 0.8582, 'Macro F1-Score': 0.856, 'Macro Precision': 0.8571, 'Macro Recall': 0.8551} \n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "Training Logistic Regression \n",
            "\n",
            "Logistic Regression Results: {'Accuracy': 0.9855, 'Macro F1-Score': 0.9853, 'Macro Precision': 0.9841, 'Macro Recall': 0.9869} \n",
            "\n",
            "Best Logistic Regression parameters: {'C': 100, 'solver': 'liblinear'} \n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "Training SVM \n",
            "\n",
            "SVM Results: {'Accuracy': 1.0, 'Macro F1-Score': 1.0, 'Macro Precision': 1.0, 'Macro Recall': 1.0} \n",
            "\n",
            "Best SVM parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'} \n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "Haberman Dataset \n",
            "\n",
            "Training Naive Bayes \n",
            "\n",
            "Naive Bayes Results: {'Accuracy': 0.7581, 'Macro F1-Score': 0.57, 'Macro Precision': 0.686, 'Macro Recall': 0.572} \n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "Training Logistic Regression \n",
            "\n",
            "Logistic Regression Results: {'Accuracy': 0.7581, 'Macro F1-Score': 0.5338, 'Macro Precision': 0.7147, 'Macro Recall': 0.5516} \n",
            "\n",
            "Best Logistic Regression parameters: {'C': 0.001, 'solver': 'liblinear'} \n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "Training SVM \n",
            "\n",
            "SVM Results: {'Accuracy': 0.7258, 'Macro F1-Score': 0.5127, 'Macro Precision': 0.5772, 'Macro Recall': 0.5299} \n",
            "\n",
            "Best SVM parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'} \n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}